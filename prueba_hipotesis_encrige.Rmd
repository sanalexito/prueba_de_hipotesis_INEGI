---
title: "ENCRIGE 2020"
subtitle: <img src="~/logoINEGI.png" width="120" align="right"/>
date: "12/8/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Pruebas de hipótesis

Para el cálculo de pruebas de hipotesis de la diferencia entre medias, cuando las varianzas no son iguales, se usa la prueba de Welch.

La fórmula para el estadístico de prueba en este caso es:

$$
t = \frac{\mu_1 - \mu_2}{\sqrt{\frac{\sigma_1^2}{n_1} +\frac{\sigma_2^2}{n_2}}},
$$
y puede suponerse en general que 
$t \sim N\left(\mu_1 -\mu_2, \sqrt{\frac{\sigma_1^2}{n_1} +\frac{\sigma_2^2}{n_2}}\right).$

Si bien existen varios criterios para fijar los grados de libertad, en este caso se usa la expresión:

$$
gl = \frac{\left[\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2} \right]^2}{
\frac{1}{n_1 -1}\left[\frac{\sigma_1^2}{n_1}\right]^2 + 
\frac{1}{n_2 -1}\left[\frac{\sigma_2^2}{n_2}\right]^2
}
$$

Así, para una prueba de hipótesis de dos colas de la forma:

$$
\begin{cases} 
  H_0:\mu_1 - \mu_2 =0 \\
  H_1:\mu_1 - \mu_2 \neq 0 
\end{cases} 
$$
la región de aceptación puede verse como

$$
A = \left(
\mu_1 - \mu_2 - z_\frac{\alpha}{2}\sqrt{\frac{\sigma_1^2}{n_1} +\frac{\sigma_2^2}{n_2}}, 
\mu_1 - \mu_2 + z_\frac{\alpha}{2}\sqrt{\frac{\sigma_1^2}{n_1} +\frac{\sigma_2^2}{n_2}}
\right) 
$$

De esta manera es obvio que **el tamaño de la región de aceptación** es 
$$
2*\left[\mu_1 - \mu_2 + z_\frac{\alpha}{2}\sqrt{\frac{\sigma_1^2}{n_1} +\frac{\sigma_2^2}{n_2}}\right]
$$

Sin embargo, es preciso mencionar que no debe hacerse la prueba de hipótesis comparando el estadístico de prueba versus el tamaño de la región de aceptación directamente. Esta es una posible confusión que aparece a la hora de construir lo estadísticos de prueba para contrastes bilaterales.


Por otra parte, con la información pertinente podemos apoyarnos de las tablas estadísticas para conocer la información necesaria para llevar a cabo la prueba de hipótesis de forma correcta.

![Tabla 1. ](~/tabla-t.PNG)



## Ejemplo de una prueba de hipótesis

Considermos los siguientes dos conjuntos de datos 
$$x = \{19.8,20.4,19.6,17.8,18.5,18.9,18.3,18.9,19.5,22.0\}$$
y
$$y = \{28.2,26.6,20.1,23.3,25.2,22.1,17.7,27.6,20.6,13.7,23.2,17.5,20.6,18.0,23.9,21.6,24.3,20.4,24.0,13.2\},$$
para los que obtenemos las respectivas medias  $\mu_1$ y $\mu_2$:

```{r ,echo= FALSE}
x = c(19.8,20.4,19.6,17.8,18.5,18.9,18.3,18.9,19.5,22.0)
y = c(28.2,26.6,20.1,23.3,25.2,22.1,17.7,27.6,20.6,13.7,23.2,17.5,20.6,18.0,23.9,21.6,24.3,20.4,24.0,13.2)

mu_x<- mean(x)
mu_y<- mean(y)

sigma_x <- sd(x)
sigma_y <- sd(y)

Estadistico_t <-ifelse(( mu_x- mu_y)/sqrt(sigma_x^2/10 + sigma_y^2/20)<0,
                       (mu_x- mu_y)/sqrt(sigma_x^2/10 + sigma_y^2/20),
                      -(mu_x- mu_y)/sqrt(sigma_x^2/10 + sigma_y^2/20))

```

```{r ,echo= F}
mu_x; mu_y
```

Supongamos que estamos interesados en realizar la prueba de hipótesis correspondiente para saber si existen cambios significativos entre $\mu_1$ y $\mu_2$ con un nivel de confianza del $95 \%$. De esta manera es necesario obtener los correspondientes errores estándar de cada conjunto; por lo que haciendo el cálculo llegamos a que $\sigma_1$ y $\sigma_2$ son:
```{r ,echo= F}
sigma_x; sigma_y
```

Sustityendo estos valores en la primera fórmula calculamos el **estadístico de prueba t**:
```{r, echo= F}
Estadistico_t
```

Y los **grados de libertad** en este caso son 
```{r, echo= F}
numerador <- (sigma_x^2/10 + sigma_y^2/20)^2
denominador <- (sigma_x^2/10)^2/9 + (sigma_y^2/20)^2/19

gl <- numerador/denominador
gl
```



# Región de aceptación y desarrollo de la prueba.

Para el caso que nos interesa suponemos $H_0$. Es decir $\mu_1 -\mu_2 =0$, por lo que con la información que tenemos llegamos a que $z_\frac{\alpha}{2}=2.06,$ de donde se sigue que
\begin{eqnarray}
A & = &\left(
      \mu_1 - \mu_2 - z_\frac{\alpha}{2}\sqrt{\frac{\sigma_1^2}{n_1} +\frac{\sigma_2^2}{n_2}}, 
      \mu_1 - \mu_2 + z_\frac{\alpha}{2}\sqrt{\frac{\sigma_1^2}{n_1} +\frac{\sigma_2^2}{n_2}}
      \right) \\
  & = & \left(
       - 2.06*\sqrt{\frac{1.203744^2}{10} +\frac{4.137111^2}{20}},        
         2.06*\sqrt{\frac{1.203744^2}{10} +\frac{4.137111^2}{20}}
        \right) \\
  & = & (-2.060705, 2.060705 )    
\end{eqnarray}


Vemos así que el estimador de prueba no está en la region de aceptación, por lo que la prueba se inclina a favor de la hipótesis alternativa.

Otra manera de obtener la misma conclusion es usando el p-value. En este caso, si el p-value está por debajo del nivel de significancia se rechaza la hipótesis nula. Tenemos entonces, al hacer el cálculo, que

```{r,echo=F}
p_value <- pt(q = Estadistico_t, df = 24.496) + (1 - pt(q = -Estadistico_t, df = 24.496))
paste0("p_value =",p_value)
```
de donde se sigue el rechazo de $H_0$.


Una tercera forma, bastante usada cuando los tamaños de los conjutos son grandes, es que se rechaza $H_0$ si $|t| > 1.96$. Así, es fácil ver que se rechaza la hipótesis nula porque
$|t| = 2.219 > 1.96.$

Usando R obtenemos el mismo resultado con la instrucción 
```{r}
t.test(x,y, alternative = "two.sided", var.equal = F)

```



# Prueba de hipótesis para la ENCRIGE 2020

Las PH que se generaron la ENCRIGE fueron realizadas usando el estadístico 
$$ 
\hat{t} = \frac{\mu_1 - \mu_2}{\sqrt{\sigma_1^2 + \sigma_2^2}}.
$$
En este caso el contraste se puede hacer de dos maneras: (i) construyendo el valor $D$ mediante la función de distribución ó (ii) usando el valor de $z_\frac{\alpha}{2}$ para el nivel de confianza de $95 \%$. 

Para el primer caso, en R se puede usar el comando

$$D = 2*abs(pnorm(\hat{t}))$$

y posteriormente determinar si existe diferencia entre las medias cuando se compara este valor con el nivel de significancia. Es decir, que se rechaza la hipótesis nula (de que las medias son iguales) cuando 

$$D\geq 0.05$$

Cabe mencionar que el comando "pnorm" proporciona la función de distribución y el argumento se sigue a raíz de que al ser una prueba de dos colas, el area bajo la curva para la región de rechazo es la suma de ambos extremos. Así que se multiplica por 2 aprovechando que en este caso la función de distribución es par.

Al replicar el ejemplo con el que trabajamos previamente se tiene que $\hat{t} = -0.5152395$ y $D = 0.6063856$. 

De esta forma se llega a que 
$$D = 0.6063856\geq 0.05$$
Lo que **proporciona información para NO RECHAZAR $H_0: \mu_1 - \mu_2=0$**. Lo que haría concluir que se acepta que las medias son iguales.

El segundo caso es inmediato al considerar $|t| = 0.5152$. Y es que 
$$|t| = 0.5152 \leq 1.96$$ por lo que no se rechaza $H_0.$


# Comparación de los contrastes usando $t$ y $\hat{t}$

De las pruebas de hipótesis que se tienen se tomará como ejemplo la diapositiva 28 de la presentación nacional de la ENCRIGE 2020.
```{r,echo=F}
d_26<-openxlsx::read.xlsx("~/d_26.xlsx",1)
d_2016 <- d_26[2:8,c(1:3)]
d_2020 <- d_26[2:8,c(7:9)]
colnames(d_2016) <- c("ENCRIGE_2016","REL","SE")
colnames(d_2020) <- c("ENCRIGE_2016","REL","SE")
d_2016[,2] <- as.numeric(d_2016[,2])
d_2020[,2] <- as.numeric(d_2020[,2])

d_2016[,3] <- as.numeric(d_2016[,3])
d_2020[,3] <- as.numeric(d_2020[,3])

d_2016
d_2020
d <- cbind(d_2016,NA,d_2020)

```

Usando el estadístico $t$ se tiene que el resultado de la prueba de hipotesis es:
```{r}
d$Estadistico_t <-ifelse(
  (d_2016[,2]- d_2020[,2])/sqrt(d_2016[,3]^2 + d_2020[,3]^2)<0,
  (d_2016[,2]- d_2020[,2])/sqrt(d_2016[,3]^2 + d_2020[,3]^2),
 -(d_2016[,2]- d_2020[,2])/sqrt(d_2016[,3]^2 + d_2020[,3]^2))

d$prueba <- ifelse(abs(d$Estadistico_t)>1.96, "H_1","H_0")
d$prueba
```

Por otro lado, al usar $\hat{t}$ 
```{r}
d$distribucion <- 2*abs(pnorm(d$Estadistico_t))

d$cambio_Sig<-ifelse(d$distribucion >= 0.05,"H_0","H_1")
d$cambio_Sig

d$cambio_Sig==d$prueba
```

Para ver la tendencia de los datos se usa el cambio absoluto que vamos a denotar como $\Delta_{abs}$ y que está dado como la diferencia entre los periodos. Así se tiene que el cambio absoluto está dado como
```{r}
d$cambio_abs <- d_2020[,2] - d_2016[,2]
d$cambio_abs
```
De donde se sigue la conclusión usando la instrucción:
```{r}
d$Tendencia <- ifelse(d$cambio_Sig == "H_1" & d$cambio_abs<0, "Bajó",
                           ifelse(d$cambio_Sig == "H_1" & d$cambio_abs>0, "Subió", "Igual"))
d$Tendencia
```

Esta misma conclusión se obtiene cuando se usa la otra forma, que involucra al estadístico de prueba "d$prueba"

```{r}
d$Tendencia_bis <- ifelse(d$prueba == "H_1" & d$cambio_abs<0, "Bajó",
                           ifelse(d$prueba == "H_1" & d$cambio_abs>0, "Subió", "Igual"))
d$Tendencia_bis
```


> Made by: Alejandro Sánchez Peralta

